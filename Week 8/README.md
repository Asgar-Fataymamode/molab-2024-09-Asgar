# [FaceMesh](https://github.com/mobilelabclass-itp/07-FaceMesh)

- Face Mesh with ARKit and SwiftUI

[based on appcoda/Face-Mesh](https://github.com/appcoda/Face-Mesh)

- BridgeView uses UIViewControllerRepresentable to create a bridge between UIKit interface code and SwiftUI
- disabled display of UIKit label, replaced by @Binding var analysis
- project settings upgraded to iOS 16.0
- renamed "True Depth" -> FaceMesh

# --
 
This app leverages face mesh technology to recognize and respond to various facial expressions in real-time. By identifying key expressions such as smiling, being angry, shocked, sad etc the app provides an interactive and fun experience by generating corresponding emojis on the screen. This dynamic emoji overlay feature allows users to see expressive emojis appear instantly as their facial expressions change, creating an engaging and entertaining experience.


For the full tutorial, please refer to this link:

https://www.appcoda.com/arkit-face-tracking
